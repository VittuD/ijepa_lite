# @package _global_
defaults:
  - /task: pretrain
  - /model: vit_torchvision
  - /predictor: base
  - /data: stl10
  - /masking: block
  - /loss: vanilla
  - /optim: adamw
  - /sched: warmup_cosine
  - /train: pretrain
  - _self_

model:
  arch: vit_small_16
  image_size: 96
  patch_size: 16
  embed_dim: 384
  num_heads: 6
  depth: 12
  ema_momentum: [0.996, 0.996]

masking:
  target_ratio: 0.25
  context_ratio: 0.75

data:
  root: ${oc.env:STL10_ROOT,/scratch/ijepa_lite/data}
  pretrain_split: unlabeled
  batch_size: 128
  num_workers: 4
  download: true

optim:
  lr: 3e-4
  weight_decay: 0.05

sched:
  warmup_epochs: 1
  min_lr: 1e-6

train:
  epochs: 100
  log_every: 20
  save_every_epochs: 1
  amp: true
  grad_clip_norm: 1.0