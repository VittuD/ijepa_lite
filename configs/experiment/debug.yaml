# @package _global_
defaults:
  - /task: pretrain
  - /model: vit_torchvision
  - /predictor: base
  - /data: stl10
  - /masking: block
  - /loss: vanilla
  - /optim: adamw
  - /sched: warmup_cosine
  - /train: pretrain
  - _self_

model:
  arch: vit_small_16
  image_size: 96
  patch_size: 16
  embed_dim: 384
  num_heads: 6
  depth: 4
  ema_momentum: [0.99, 0.99]

data:
  root: ${oc.env:STL10_ROOT,/scratch/ijepa_lite/data}
  pretrain_split: unlabeled
  batch_size: 32
  num_workers: 2
  download: true

train:
  epochs: 1
  log_every: 10
  save_every_epochs: 1
  amp: true